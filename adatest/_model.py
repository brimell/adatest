import numpy as np
import shap
import urllib.request
import json
import os
import ssl

class Model():
    """ This wraps models used in AdaTest so that have a consistent interface.

    This should eventually just be the Model class from SHAP, but we keep a simple version here for now
    so we can easily update it during initial development.
    """

    def __new__(cls, model, *args, **kwargs):
        """ If we are wrapping a model that is already a Model, we just return it.
        """
        if shap.utils.safe_isinstance(model, "adatest.Model") or shap.utils.safe_isinstance(model, "shap.models.Model"):
            return model
        else:
            return super().__new__(cls)
    
    def __init__(self, model, output_names=None,url="",api_key="", **kwargs):
        """ Build a new model by wrapping the given model object.

        Parameters
        ----------
        model : object
            The model to wrap. This can be a plain python function that accepts a list of strings and returns either
            a vector of probabilities or another string. It can also be a transformers pipeline object (we try to wrap
            common model types transparently).

        output_names : list of str, optional
            The names of the outputs of the model. If not given, we try to infer them from the model.
        """

        # finish early if we are wrapping an object that is already a Model
        if shap.utils.safe_isinstance(model, "adatest.Model") or shap.utils.safe_isinstance(model, "shap.models.Model"):
            if output_names is not None:
                self.output_names = output_names
            assert len(kwargs) == 0
            return

        # get outputs names from the model if it has them and we don't
        if output_names is None and hasattr(model, "output_names"):
            output_names = model.output_names

        # If we are in the base class we check to see if we should rebuild the model as a specialized subclass
        if self.__class__ is Model:
            
            # wrap transformer pipeline objects for convenience
            if shap.utils.safe_isinstance(model, "transformers.pipelines.text_classification.TextClassificationPipeline"):
                self.__class__ = shap.models.TransformersPipeline
                shap.models.TransformersPipeline.__init__(self, model, **kwargs)
                if output_names is not None: # Override output names if user supplied
                    self.output_names = output_names

            elif shap.utils.safe_isinstance(model, "transformers.pipelines.text_generation.TextGenerationPipeline"):
                self.__class__ = TransformersTextGenerationPipeline
                TransformersTextGenerationPipeline.__init__(self, model, **kwargs)  
            elif model == "EntailmentAPI":
                self.__class__ = EntailmentAPI
                EntailmentAPI.__init__(self, model,url,api_key, **kwargs)         
            else:
                self.inner_model = model
                self.output_names = output_names

    def __call__(self, *args, **kwargs):
        return np.array(self.inner_model(*args, **kwargs))

    
class TransformersTextGenerationPipeline(Model):
    """ This wraps the transformer text generation pipeline object to match the Model API.

    TODO: move this to SHAP.
    """
    def __init__(self, pipeline):
        self._inner_model = pipeline
        self.output_names = None

    def __call__(self, strings):
        inner_out = self._inner_model(strings)
        out = []
        for s, data in zip(strings, inner_out):
            out.append(data[0]["generated_text"][len(s):]) # remove the input text from the output
        return out

class EntailmentAPI(Model):
    def __init__(self,model, url, api_key):
        self._inner_model = APICaller(url, api_key)
        self.output_names = None
    
    def __call__(self,sequences,candidate_labels,hypothesis_template,multi_class= False, th = 0.95):
        out = []
        if isinstance(sequences,str):
            sequences = [sequences]
        for seq in sequences:
            if seq == "":
                #manual patch for empty seq generated by neox
                seq = "[EMPTYSEQ]"
            inner_out = self._inner_model(seq,candidate_labels,hypothesis_template,multi_class,th)
            """
            try:
                inner_out = self._inner_model(seq,candidate_labels,hypothesis_template)
            
            except:
                inner_out = [[x,np.nan] for x in candidate_labels]
            """
            scores = [x[1] for x in inner_out]
            label_in_score_order = [x[0] for x in inner_out]
            out.append({'sequence':seq,'labels':label_in_score_order,'scores':scores})
        return out
            
class APICaller():

    def __init__(self,url, api_key):
        self.url = url
        self.headers = headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'entailment-phrases' }
    def __call__(self,seq,candidate_labels,hypothesis_template,multi_class, th):
        data = {"utterance": seq, "labels":candidate_labels, "hypothesis": hypothesis_template,"multiclass":multi_class,"threshold":th}
        body = str.encode(json.dumps(data))

        req = urllib.request.Request(self.url , body, self.headers)

        response = urllib.request.urlopen(req)
        result = response.read()
        try:
            response = urllib.request.urlopen(req)
            result = response.read()
            print(body)
            print(result)
            return json.loads(result)
        except urllib.error.HTTPError as error:
            print("The request failed with status code: " + str(error.code))

            # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure
            print(error.info())
            print(error.read().decode("utf8", 'ignore'))
            return [[x,np.nan] for x in candidate_labels]